{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "from os import listdir\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_normalize(arr):\n",
    "    \"\"\"\n",
    "    Perform Positive Global Standardization on input array and return it.\n",
    "    Arguments:\n",
    "        arr: 2-dimensional image array containing int or float values\n",
    "    Returns:\n",
    "        arr: positive globally standardized arr of float values\n",
    "    \"\"\"\n",
    "    arr = arr.astype('float32')\n",
    "    mean, stand_dev = arr.mean(), arr.std()\n",
    "    arr = (arr-mean)/stand_dev\n",
    "    arr = np.clip(arr, -1, 1)\n",
    "    arr = (arr+1)/2\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_list, image_size):\n",
    "    \"\"\"\n",
    "    Read images, resize and normalize them. \n",
    "    Arguments:\n",
    "        dir_list: list of strings representing file directories.\n",
    "    Returns:\n",
    "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
    "        y: A numpy array with shape = (#_examples, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    # load all images in a directory\n",
    "    X = []\n",
    "    y = []\n",
    "    image_width, image_height = image_size\n",
    "    \n",
    "    for directory in dir_list:\n",
    "        for filename in listdir(directory):\n",
    "            # load the image\n",
    "            image = cv2.imread(directory + '/' + filename)\n",
    "            # crop the brain and ignore the unnecessary rest part of the image\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            # resize image\n",
    "            image = cv2.resize(image, dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n",
    "            # normalize values\n",
    "            image = scale_and_normalize(image)\n",
    "            # convert image to numpy array and append it to X\n",
    "            X.append(image)\n",
    "            # append a value of 1 to the target array if the image\n",
    "            # is in the folder named 'yes', otherwise append 0.\n",
    "            if directory[-3:] == 'yes':\n",
    "                y.append([1])\n",
    "            else:\n",
    "                y.append([0])\n",
    "                \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Shuffle the data\n",
    "    X, y = shuffle(X, y)\n",
    "    \n",
    "    print(f'Number of examples is: {len(X)}')\n",
    "    print(f'X shape is: {X.shape}')\n",
    "    print(f'y shape is: {y.shape}')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples is: 253\n",
      "X shape is: (253, 240, 240)\n",
      "y shape is: (253, 1)\n"
     ]
    }
   ],
   "source": [
    "# Specify standard dimensions, load data\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = (240, 240)\n",
    "X, y = load_data(['../data/JPG_Brain_Scans/yes', '../data/JPG_Brain_Scans/no'], (IMG_WIDTH, IMG_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add channel dimension to X to allow for model training\n",
    "\n",
    "X = X.reshape(-1, 240, 240, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets, retain 20% of data for testing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate ImageDataGenerator to perform rotations/flips on training dataset\n",
    "\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(rotation_range=30,\n",
    "                                                          horizontal_flip=True,\n",
    "                                                          vertical_flip=True,\n",
    "                                                          validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "        keras.Input(shape=(240, 240, 1)),\n",
    "        keras.layers.Conv2D(32, 3, strides=(1, 1), activation='relu', data_format='channels_last', name='conv0'),\n",
    "        keras.layers.MaxPool2D((2, 2), name='max_pool0'),\n",
    "        keras.layers.BatchNormalization(name='bn0'),\n",
    "        keras.layers.Conv2D(64, 3, strides=(1, 1), activation='relu', data_format='channels_last', name='conv1'),\n",
    "        keras.layers.MaxPool2D((2, 2), name='max_pool1'),\n",
    "        keras.layers.BatchNormalization(name='bn1'),\n",
    "        keras.layers.Conv2D(128, 3, strides=(1, 1), activation='relu', data_format='channels_last', name='conv2'),\n",
    "        keras.layers.MaxPool2D((2, 2), name='max_pool2'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv0 (Conv2D)               (None, 238, 238, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pool0 (MaxPooling2D)     (None, 119, 119, 32)      0         \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 119, 119, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 117, 117, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 58, 58, 64)        0         \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 58, 58, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pool2 (MaxPooling2D)     (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 100353    \n",
      "=================================================================\n",
      "Total params: 193,409\n",
      "Trainable params: 193,217\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# View summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 8s 1s/step - loss: 134.7169 - binary_accuracy: 0.4687 - val_loss: 24.7163 - val_binary_accuracy: 0.3922\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 30.3323 - binary_accuracy: 0.7186 - val_loss: 368.9748 - val_binary_accuracy: 0.3922\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 73.9912 - binary_accuracy: 0.6346 - val_loss: 26.5297 - val_binary_accuracy: 0.4706\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 14.7012 - binary_accuracy: 0.7613 - val_loss: 16.6152 - val_binary_accuracy: 0.7843\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 19.1044 - binary_accuracy: 0.7705 - val_loss: 11.6098 - val_binary_accuracy: 0.6863\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 11.7859 - binary_accuracy: 0.8116 - val_loss: 131.4888 - val_binary_accuracy: 0.3922\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 13.2116 - binary_accuracy: 0.8358 - val_loss: 52.0542 - val_binary_accuracy: 0.4314\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.9097 - binary_accuracy: 0.8930 - val_loss: 33.3364 - val_binary_accuracy: 0.4510\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 9.4394 - binary_accuracy: 0.8436 - val_loss: 37.3082 - val_binary_accuracy: 0.4510\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.2700 - binary_accuracy: 0.9492 - val_loss: 43.3292 - val_binary_accuracy: 0.4706\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 6.4880 - binary_accuracy: 0.8529 - val_loss: 31.9425 - val_binary_accuracy: 0.5686\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 6.5040 - binary_accuracy: 0.9209 - val_loss: 14.1330 - val_binary_accuracy: 0.6275\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.4878 - binary_accuracy: 0.9636 - val_loss: 26.7226 - val_binary_accuracy: 0.5490\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.3321 - binary_accuracy: 0.9793 - val_loss: 21.8892 - val_binary_accuracy: 0.5686\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.7719 - binary_accuracy: 0.9752 - val_loss: 18.5638 - val_binary_accuracy: 0.5882\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.0328 - binary_accuracy: 0.9046 - val_loss: 21.8410 - val_binary_accuracy: 0.7059\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.9701 - binary_accuracy: 0.9753 - val_loss: 29.1575 - val_binary_accuracy: 0.7059\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.3815 - binary_accuracy: 0.9476 - val_loss: 33.8131 - val_binary_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.0188 - binary_accuracy: 0.9529 - val_loss: 11.7520 - val_binary_accuracy: 0.8039\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.2128 - binary_accuracy: 0.9962 - val_loss: 33.1429 - val_binary_accuracy: 0.6275\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 7s 994ms/step - loss: 0.6894 - binary_accuracy: 0.9796 - val_loss: 11.4038 - val_binary_accuracy: 0.8235\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.8564 - binary_accuracy: 0.9559 - val_loss: 32.0878 - val_binary_accuracy: 0.6863\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 9.1222e-14 - binary_accuracy: 1.0000 - val_loss: 21.3474 - val_binary_accuracy: 0.7647\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.0491e-14 - binary_accuracy: 1.0000 - val_loss: 21.3308 - val_binary_accuracy: 0.7647\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0756 - binary_accuracy: 0.9945 - val_loss: 25.7864 - val_binary_accuracy: 0.7647\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.6224e-10 - binary_accuracy: 1.0000 - val_loss: 28.2065 - val_binary_accuracy: 0.7255\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0036 - binary_accuracy: 0.9988 - val_loss: 38.5470 - val_binary_accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.2770 - binary_accuracy: 0.9719 - val_loss: 15.6723 - val_binary_accuracy: 0.8039\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.4969 - binary_accuracy: 0.9710 - val_loss: 27.2833 - val_binary_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.5544 - binary_accuracy: 0.9947 - val_loss: 40.2666 - val_binary_accuracy: 0.6471\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 6.9054e-21 - binary_accuracy: 1.0000 - val_loss: 26.1154 - val_binary_accuracy: 0.6863\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.1423e-12 - binary_accuracy: 1.0000 - val_loss: 20.2041 - val_binary_accuracy: 0.7059\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.3152e-04 - binary_accuracy: 1.0000 - val_loss: 18.0030 - val_binary_accuracy: 0.8039\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.8899e-06 - binary_accuracy: 1.0000 - val_loss: 16.9975 - val_binary_accuracy: 0.8039\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.7365e-07 - binary_accuracy: 1.0000 - val_loss: 16.1710 - val_binary_accuracy: 0.8039\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.5915e-10 - binary_accuracy: 1.0000 - val_loss: 15.5364 - val_binary_accuracy: 0.8431\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.0811e-10 - binary_accuracy: 1.0000 - val_loss: 14.9281 - val_binary_accuracy: 0.8431\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.5276e-09 - binary_accuracy: 1.0000 - val_loss: 14.3246 - val_binary_accuracy: 0.8627\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 6.9734e-11 - binary_accuracy: 1.0000 - val_loss: 13.8586 - val_binary_accuracy: 0.8627\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.7123e-12 - binary_accuracy: 1.0000 - val_loss: 13.4285 - val_binary_accuracy: 0.8627\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.2085e-12 - binary_accuracy: 1.0000 - val_loss: 13.1566 - val_binary_accuracy: 0.8627\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.1657e-12 - binary_accuracy: 1.0000 - val_loss: 12.9895 - val_binary_accuracy: 0.8627\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.0578e-08 - binary_accuracy: 1.0000 - val_loss: 12.8399 - val_binary_accuracy: 0.8627\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.1917e-11 - binary_accuracy: 1.0000 - val_loss: 12.7330 - val_binary_accuracy: 0.8824\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.9068e-09 - binary_accuracy: 1.0000 - val_loss: 12.7070 - val_binary_accuracy: 0.8824\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.1943e-06 - binary_accuracy: 1.0000 - val_loss: 12.6964 - val_binary_accuracy: 0.8824\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 7s 995ms/step - loss: 2.0337e-09 - binary_accuracy: 1.0000 - val_loss: 12.6914 - val_binary_accuracy: 0.8824\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.0251e-09 - binary_accuracy: 1.0000 - val_loss: 12.7016 - val_binary_accuracy: 0.8824\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 9.3775e-11 - binary_accuracy: 1.0000 - val_loss: 12.7037 - val_binary_accuracy: 0.8824\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.1651e-05 - binary_accuracy: 1.0000 - val_loss: 12.7196 - val_binary_accuracy: 0.8824\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.1133e-12 - binary_accuracy: 1.0000 - val_loss: 12.7972 - val_binary_accuracy: 0.8824\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.4385e-19 - binary_accuracy: 1.0000 - val_loss: 12.8371 - val_binary_accuracy: 0.8824\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.3504e-19 - binary_accuracy: 1.0000 - val_loss: 12.8535 - val_binary_accuracy: 0.8824\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.1173e-19 - binary_accuracy: 1.0000 - val_loss: 12.8686 - val_binary_accuracy: 0.8824\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.4940e-20 - binary_accuracy: 1.0000 - val_loss: 12.8810 - val_binary_accuracy: 0.8824\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.6736e-18 - binary_accuracy: 1.0000 - val_loss: 12.8891 - val_binary_accuracy: 0.8824\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.3237e-18 - binary_accuracy: 1.0000 - val_loss: 12.8947 - val_binary_accuracy: 0.8824\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.8013e-20 - binary_accuracy: 1.0000 - val_loss: 12.9202 - val_binary_accuracy: 0.9020\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 7s 994ms/step - loss: 6.9156e-20 - binary_accuracy: 1.0000 - val_loss: 13.0080 - val_binary_accuracy: 0.8824\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 7s 994ms/step - loss: 8.7409e-21 - binary_accuracy: 1.0000 - val_loss: 13.1315 - val_binary_accuracy: 0.8824\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 7s 995ms/step - loss: 2.1906e-18 - binary_accuracy: 1.0000 - val_loss: 13.2595 - val_binary_accuracy: 0.8824\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 7s 998ms/step - loss: 1.4024e-22 - binary_accuracy: 1.0000 - val_loss: 13.3808 - val_binary_accuracy: 0.8824\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.8072e-21 - binary_accuracy: 1.0000 - val_loss: 13.4928 - val_binary_accuracy: 0.8824\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.5596e-20 - binary_accuracy: 1.0000 - val_loss: 13.6012 - val_binary_accuracy: 0.8824\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.3825e-19 - binary_accuracy: 1.0000 - val_loss: 13.7070 - val_binary_accuracy: 0.8824\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.4788e-20 - binary_accuracy: 1.0000 - val_loss: 13.8101 - val_binary_accuracy: 0.8824\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 6.2346e-22 - binary_accuracy: 1.0000 - val_loss: 13.9043 - val_binary_accuracy: 0.8824\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.0451e-15 - binary_accuracy: 1.0000 - val_loss: 13.9994 - val_binary_accuracy: 0.8824\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.1338e-20 - binary_accuracy: 1.0000 - val_loss: 14.0897 - val_binary_accuracy: 0.8824\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.1781e-21 - binary_accuracy: 1.0000 - val_loss: 14.1788 - val_binary_accuracy: 0.8824\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.1635e-20 - binary_accuracy: 1.0000 - val_loss: 14.2612 - val_binary_accuracy: 0.8824\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.0460e-19 - binary_accuracy: 1.0000 - val_loss: 14.3393 - val_binary_accuracy: 0.8824\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.6268e-20 - binary_accuracy: 1.0000 - val_loss: 14.4107 - val_binary_accuracy: 0.8824\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.1524e-20 - binary_accuracy: 1.0000 - val_loss: 14.4822 - val_binary_accuracy: 0.8824\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.4437e-19 - binary_accuracy: 1.0000 - val_loss: 14.5457 - val_binary_accuracy: 0.8824\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.7288e-19 - binary_accuracy: 1.0000 - val_loss: 14.6044 - val_binary_accuracy: 0.8824\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 7s 1000ms/step - loss: 7.7403e-19 - binary_accuracy: 1.0000 - val_loss: 14.6624 - val_binary_accuracy: 0.8824\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.5358e-21 - binary_accuracy: 1.0000 - val_loss: 14.7215 - val_binary_accuracy: 0.8824\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.6793e-21 - binary_accuracy: 1.0000 - val_loss: 14.7746 - val_binary_accuracy: 0.8824\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.5399e-17 - binary_accuracy: 1.0000 - val_loss: 14.8261 - val_binary_accuracy: 0.8824\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.4635e-22 - binary_accuracy: 1.0000 - val_loss: 14.8760 - val_binary_accuracy: 0.8824\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.8145e-21 - binary_accuracy: 1.0000 - val_loss: 14.9208 - val_binary_accuracy: 0.8824\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 6.0147e-21 - binary_accuracy: 1.0000 - val_loss: 14.9611 - val_binary_accuracy: 0.8824\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.8474e-19 - binary_accuracy: 1.0000 - val_loss: 15.0048 - val_binary_accuracy: 0.8824\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 7s 985ms/step - loss: 2.1946e-21 - binary_accuracy: 1.0000 - val_loss: 15.0447 - val_binary_accuracy: 0.8824\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 7s 997ms/step - loss: 5.2168e-22 - binary_accuracy: 1.0000 - val_loss: 15.0800 - val_binary_accuracy: 0.8824\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.8554e-21 - binary_accuracy: 1.0000 - val_loss: 15.1163 - val_binary_accuracy: 0.8824\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 9.0266e-21 - binary_accuracy: 1.0000 - val_loss: 15.1484 - val_binary_accuracy: 0.8824\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.6864e-20 - binary_accuracy: 1.0000 - val_loss: 15.1831 - val_binary_accuracy: 0.8824\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 7s 999ms/step - loss: 4.1224e-21 - binary_accuracy: 1.0000 - val_loss: 15.2133 - val_binary_accuracy: 0.8824\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.1690e-19 - binary_accuracy: 1.0000 - val_loss: 15.2398 - val_binary_accuracy: 0.8824\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.3549e-19 - binary_accuracy: 1.0000 - val_loss: 15.2655 - val_binary_accuracy: 0.8824\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.5876e-20 - binary_accuracy: 1.0000 - val_loss: 15.2922 - val_binary_accuracy: 0.8824\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.4438e-19 - binary_accuracy: 1.0000 - val_loss: 15.3191 - val_binary_accuracy: 0.8824\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.0137e-20 - binary_accuracy: 1.0000 - val_loss: 15.3390 - val_binary_accuracy: 0.8824\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.1408e-18 - binary_accuracy: 1.0000 - val_loss: 15.3623 - val_binary_accuracy: 0.8824\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.0007e-21 - binary_accuracy: 1.0000 - val_loss: 15.3800 - val_binary_accuracy: 0.8824\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.7166e-18 - binary_accuracy: 1.0000 - val_loss: 15.3957 - val_binary_accuracy: 0.8824\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.2248e-20 - binary_accuracy: 1.0000 - val_loss: 15.4152 - val_binary_accuracy: 0.8824\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.0529e-21 - binary_accuracy: 1.0000 - val_loss: 15.4318 - val_binary_accuracy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "neural_net = model.fit(X_train, y_train, batch_size=32, epochs = 100, shuffle=True, validation_data = (X_test, y_test), callbacks=[tensorboard_callback, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 8s 1s/step - loss: 143.3309 - binary_accuracy: 0.4840 - val_loss: 18.7952 - val_binary_accuracy: 0.6078\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 7s 1s/step - loss: 64.2438 - binary_accuracy: 0.6639 - val_loss: 21.4390 - val_binary_accuracy: 0.6275\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 7s 1s/step - loss: 55.2307 - binary_accuracy: 0.7001 - val_loss: 50.9869 - val_binary_accuracy: 0.6078\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 7s 1s/step - loss: 60.4103 - binary_accuracy: 0.5282 - val_loss: 9.9251 - val_binary_accuracy: 0.5490\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 7s 1s/step - loss: 27.9915 - binary_accuracy: 0.7793 - val_loss: 16.3217 - val_binary_accuracy: 0.5098\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 7s 1s/step - loss: 24.8574 - binary_accuracy: 0.6802 - val_loss: 44.2826 - val_binary_accuracy: 0.4118\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 7s 1s/step - loss: 12.8433 - binary_accuracy: 0.7778 - val_loss: 28.9815 - val_binary_accuracy: 0.4314\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.0708 - binary_accuracy: 0.8132 - val_loss: 25.5884 - val_binary_accuracy: 0.4314\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.5285 - binary_accuracy: 0.7959 - val_loss: 14.3882 - val_binary_accuracy: 0.4706\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 7s 1s/step - loss: 16.7411 - binary_accuracy: 0.7290 - val_loss: 8.1742 - val_binary_accuracy: 0.7059\n"
     ]
    }
   ],
   "source": [
    "# Save tensorboard callback logs for each training epoch\n",
    "\n",
    "from datetime import datetime\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_path = 'models/best_classifier.h5'\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Save best model according to its validation set binary accuracy\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_binary_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "# Fit model using ImageDataGenerator on training data, unaltered testing data\n",
    "\n",
    "neural_net = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                       epochs=100, shuffle=True,\n",
    "                       validation_data = (X_test, y_test), \n",
    "                       callbacks=[tensorboard_callback, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7058823529411765"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run 'tta_steps' of predictions on test set data which has been rotated/flipped\n",
    "# by the ImageDataGenerator and append each set of predictions to a list.\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "tta_steps = 10\n",
    "predictions = []\n",
    "\n",
    "for i in range(tta_steps):\n",
    "    preds = (model.predict(datagen.flow(X_test, batch_size=32, shuffle=False)) > 0.5).astype(\"int32\")\n",
    "    predictions.append(preds)\n",
    "\n",
    "# Compare the mode of the predictions for each image against the true label, calculate\n",
    "# accuracy\n",
    "\n",
    "np.mean(np.equal(y_test, stats.mode(predictions)[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
