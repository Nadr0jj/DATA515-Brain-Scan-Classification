{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from IPython import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "from os import listdir\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_normalize(arr):\n",
    "    arr = arr.astype('float32')\n",
    "    mean, stand_dev = arr.mean(), arr.std()\n",
    "    arr = (arr-mean)/stand_dev\n",
    "    arr = np.clip(arr, -1, 1)\n",
    "    arr = (arr+1)/2\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_list, image_size):\n",
    "    \"\"\"\n",
    "    Read images, resize and normalize them. \n",
    "    Arguments:\n",
    "        dir_list: list of strings representing file directories.\n",
    "    Returns:\n",
    "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
    "        y: A numpy array with shape = (#_examples, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    # load all images in a directory\n",
    "    X = []\n",
    "    y = []\n",
    "    image_width, image_height = image_size\n",
    "    \n",
    "    for directory in dir_list:\n",
    "        for filename in listdir(directory):\n",
    "            # load the image\n",
    "            image = cv2.imread(directory + '/' + filename)\n",
    "            # crop the brain and ignore the unnecessary rest part of the image\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            # resize image\n",
    "            image = cv2.resize(image, dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n",
    "            # normalize values\n",
    "            image = scale_and_normalize(image)\n",
    "            # convert image to numpy array and append it to X\n",
    "            X.append(image)\n",
    "            # append a value of 1 to the target array if the image\n",
    "            # is in the folder named 'yes', otherwise append 0.\n",
    "            if directory[-3:] == 'yes':\n",
    "                y.append([1])\n",
    "            else:\n",
    "                y.append([0])\n",
    "                \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Shuffle the data\n",
    "    X, y = shuffle(X, y)\n",
    "    \n",
    "    print(f'Number of examples is: {len(X)}')\n",
    "    print(f'X shape is: {X.shape}')\n",
    "    print(f'y shape is: {y.shape}')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples is: 253\n",
      "X shape is: (253, 240, 240)\n",
      "y shape is: (253, 1)\n"
     ]
    }
   ],
   "source": [
    "IMG_WIDTH, IMG_HEIGHT = (240, 240)\n",
    "X, y = load_data(['../data/JPG_Brain_Scans/yes', '../data/JPG_Brain_Scans/no'], (IMG_WIDTH, IMG_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1, 240, 240, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .33, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fad89214d60>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ended up using this ImageDataGenerator to generate random rotations/flips\n",
    "\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(rotation_range=30,\n",
    "                                                          horizontal_flip=True,\n",
    "                                                          vertical_flip=True,\n",
    "                                                          validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the generator to the train and test sets\n",
    "\n",
    "train_generator = datagen.flow(X_train, y_train)\n",
    "\n",
    "validation_generator = datagen.flow(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.Input(shape=(240, 240, 1)),\n",
    "    keras.layers.Conv2D(32, 3, strides=(1, 1), activation='relu', data_format='channels_last', name='conv0'),\n",
    "\n",
    "    #   Added additional convolutional layers after analyzing performance\n",
    "    keras.layers.Conv2D(64, 3, strides=(1, 1), activation='relu', data_format='channels_last', name='conv1'),\n",
    "    keras.layers.Conv2D(128, 3, strides=(1, 1), activation='relu', data_format='channels_last', name='conv2'),\n",
    "\n",
    "    keras.layers.MaxPool2D((2, 2), name='max_pool0'),\n",
    "    keras.layers.BatchNormalization(name='bn0'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv0 (Conv2D)               (None, 238, 238, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 236, 236, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 234, 234, 128)     73856     \n",
      "_________________________________________________________________\n",
      "max_pool0 (MaxPooling2D)     (None, 117, 117, 128)     0         \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 117, 117, 128)     512       \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 1752192)           0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 1752193   \n",
      "=================================================================\n",
      "Total params: 1,845,377\n",
      "Trainable params: 1,845,121\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = opt, metrics = ['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 26s 4s/step - loss: 31.4709 - binary_accuracy: 0.5119 - val_loss: 0.8102 - val_binary_accuracy: 0.6071\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 25s 4s/step - loss: 6.8487 - binary_accuracy: 0.6897 - val_loss: 0.5393 - val_binary_accuracy: 0.7619\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 25s 4s/step - loss: 3.7746 - binary_accuracy: 0.5991 - val_loss: 0.5171 - val_binary_accuracy: 0.7619\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 24s 4s/step - loss: 2.0967 - binary_accuracy: 0.7924 - val_loss: 0.6253 - val_binary_accuracy: 0.6071\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 24s 4s/step - loss: 1.6847 - binary_accuracy: 0.6115 - val_loss: 0.6794 - val_binary_accuracy: 0.6071\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 24s 4s/step - loss: 1.1977 - binary_accuracy: 0.6733 - val_loss: 0.6160 - val_binary_accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 25s 4s/step - loss: 1.0490 - binary_accuracy: 0.6936 - val_loss: 0.6517 - val_binary_accuracy: 0.6071\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.6283 - binary_accuracy: 0.6765 - val_loss: 0.6553 - val_binary_accuracy: 0.7024\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.6695 - binary_accuracy: 0.7604 - val_loss: 0.6553 - val_binary_accuracy: 0.6905\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.4899 - binary_accuracy: 0.7896 - val_loss: 0.6914 - val_binary_accuracy: 0.3929\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_path = 'models/best_classifier.h5'\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Save best model according to its validation set binary accuracy\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_binary_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "neural_net = model.fit(X_train, y_train, batch_size=32, epochs = 25, validation_data = (X_test, y_test), callbacks=[tensorboard_callback, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "6/6 [==============================] - 25s 4s/step - loss: 26.4510 - binary_accuracy: 0.5298 - val_loss: 1.5061 - val_binary_accuracy: 0.6094\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 24s 4s/step - loss: 10.9850 - binary_accuracy: 0.7025 - val_loss: 0.5888 - val_binary_accuracy: 0.7500\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 1.9805 - binary_accuracy: 0.7102 - val_loss: 0.6389 - val_binary_accuracy: 0.6562\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 1.8816 - binary_accuracy: 0.6597 - val_loss: 0.6714 - val_binary_accuracy: 0.5469\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.7347 - binary_accuracy: 0.7358 - val_loss: 0.6630 - val_binary_accuracy: 0.7344\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.4077 - binary_accuracy: 0.8380 - val_loss: 0.7231 - val_binary_accuracy: 0.3906\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.4347 - binary_accuracy: 0.7946 - val_loss: 0.7065 - val_binary_accuracy: 0.3594\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.4671 - binary_accuracy: 0.8127 - val_loss: 0.7480 - val_binary_accuracy: 0.3750\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.3817 - binary_accuracy: 0.8290 - val_loss: 0.6615 - val_binary_accuracy: 0.6719\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.4878 - binary_accuracy: 0.8129 - val_loss: 0.6994 - val_binary_accuracy: 0.3750\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.3185 - binary_accuracy: 0.8561 - val_loss: 0.7084 - val_binary_accuracy: 0.4062\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.3248 - binary_accuracy: 0.8540 - val_loss: 0.6748 - val_binary_accuracy: 0.4375\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.3070 - binary_accuracy: 0.9010 - val_loss: 0.6955 - val_binary_accuracy: 0.4062\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.3494 - binary_accuracy: 0.8633 - val_loss: 0.7157 - val_binary_accuracy: 0.3906\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.3414 - binary_accuracy: 0.8609 - val_loss: 0.6636 - val_binary_accuracy: 0.5781\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.2684 - binary_accuracy: 0.8816 - val_loss: 0.7002 - val_binary_accuracy: 0.3750\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.3225 - binary_accuracy: 0.8693 - val_loss: 0.7226 - val_binary_accuracy: 0.3594\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.2988 - binary_accuracy: 0.8660 - val_loss: 0.6456 - val_binary_accuracy: 0.5312\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.2894 - binary_accuracy: 0.8757 - val_loss: 0.6771 - val_binary_accuracy: 0.4531\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.3172 - binary_accuracy: 0.8670 - val_loss: 0.6893 - val_binary_accuracy: 0.4062\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.2364 - binary_accuracy: 0.8933 - val_loss: 0.7028 - val_binary_accuracy: 0.4062\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 24s 5s/step - loss: 0.3106 - binary_accuracy: 0.8929 - val_loss: 0.7042 - val_binary_accuracy: 0.3594\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 24s 5s/step - loss: 0.2743 - binary_accuracy: 0.8985 - val_loss: 0.6707 - val_binary_accuracy: 0.4688\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.2598 - binary_accuracy: 0.9041 - val_loss: 0.7191 - val_binary_accuracy: 0.3750\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.2756 - binary_accuracy: 0.8495 - val_loss: 0.7074 - val_binary_accuracy: 0.3906\n"
     ]
    }
   ],
   "source": [
    "# Test model with rotations/flips, validation accuracy seems significantly worse\n",
    "\n",
    "neural_net = model.fit_generator(train_generator, steps_per_epoch=6, epochs = 25, \n",
    "                                 validation_data=validation_generator, validation_steps=2,\n",
    "                                 callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60714286])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
