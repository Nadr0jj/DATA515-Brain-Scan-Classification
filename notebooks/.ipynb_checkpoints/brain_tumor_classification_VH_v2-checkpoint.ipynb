{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from IPython import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "from os import listdir\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_normalize(arr):\n",
    "    arr = arr.astype('float32')\n",
    "    mean, stand_dev = arr.mean(), arr.std()\n",
    "    arr = (arr-mean)/stand_dev\n",
    "    arr = np.clip(arr, -1, 1)\n",
    "    arr = (arr+1)/2\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_list, image_size):\n",
    "    \"\"\"\n",
    "    Read images, resize and normalize them. \n",
    "    Arguments:\n",
    "        dir_list: list of strings representing file directories.\n",
    "    Returns:\n",
    "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
    "        y: A numpy array with shape = (#_examples, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    # load all images in a directory\n",
    "    X = []\n",
    "    y = []\n",
    "    image_width, image_height = image_size\n",
    "    \n",
    "    for directory in dir_list:\n",
    "        for filename in listdir(directory):\n",
    "            # load the image\n",
    "            image = cv2.imread(directory + '/' + filename)\n",
    "            # crop the brain and ignore the unnecessary rest part of the image\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            # resize image\n",
    "            image = cv2.resize(image, dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n",
    "            # normalize values\n",
    "            image = scale_and_normalize(image)\n",
    "            # convert image to numpy array and append it to X\n",
    "            X.append(image)\n",
    "            # append a value of 1 to the target array if the image\n",
    "            # is in the folder named 'yes', otherwise append 0.\n",
    "            if directory[-3:] == 'yes':\n",
    "                y.append([1])\n",
    "            else:\n",
    "                y.append([0])\n",
    "                \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Shuffle the data\n",
    "    X, y = shuffle(X, y)\n",
    "    \n",
    "    print(f'Number of examples is: {len(X)}')\n",
    "    print(f'X shape is: {X.shape}')\n",
    "    print(f'y shape is: {y.shape}')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples is: 253\n",
      "X shape is: (253, 240, 240)\n",
      "y shape is: (253, 1)\n"
     ]
    }
   ],
   "source": [
    "IMG_WIDTH, IMG_HEIGHT = (240, 240)\n",
    "X, y = load_data(['../data/JPG_Brain_Scans/yes', '../data/JPG_Brain_Scans/no'], (IMG_WIDTH, IMG_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1, 240, 240, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ended up using this ImageDataGenerator to generate random rotations/flips\n",
    "\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(rotation_range=30,\n",
    "                                                          horizontal_flip=True,\n",
    "                                                          vertical_flip=True,\n",
    "                                                          validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the generator to the train and test sets\n",
    "\n",
    "train_generator = datagen.flow(X_train, y_train)\n",
    "\n",
    "validation_generator = datagen.flow(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "        keras.Input(shape=(240, 240, 1)),\n",
    "        keras.layers.Conv2D(32, 3, strides=(1, 1), activation='relu', data_format='channels_last', name='conv0'),\n",
    "        keras.layers.MaxPool2D((2, 2), name='max_pool0'),\n",
    "        keras.layers.BatchNormalization(name='bn0'),\n",
    "        #   Added additional convolutional layers after analyzing performance\n",
    "        keras.layers.Conv2D(64, 3, strides=(1, 1), activation='relu', data_format='channels_last', name='conv1'),\n",
    "        keras.layers.MaxPool2D((2, 2), name='max_pool1'),\n",
    "        keras.layers.BatchNormalization(name='bn1'),\n",
    "        keras.layers.Conv2D(128, 3, strides=(1, 1), activation='relu', data_format='channels_last', name='conv2'),\n",
    "        keras.layers.MaxPool2D((2, 2), name='max_pool2'),\n",
    "#         keras.layers.BatchNormalization(name='bn2'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7/7 [==============================] - 27s 4s/step - loss: 127.0465 - binary_accuracy: 0.5268 - val_loss: 85.2053 - val_binary_accuracy: 0.3922\n",
      "Epoch 2/25\n",
      "7/7 [==============================] - 19s 3s/step - loss: 173.6394 - binary_accuracy: 0.5162 - val_loss: 184.1372 - val_binary_accuracy: 0.4118\n",
      "Epoch 3/25\n",
      "7/7 [==============================] - 21s 3s/step - loss: 66.7520 - binary_accuracy: 0.6203 - val_loss: 26.4782 - val_binary_accuracy: 0.5686\n",
      "Epoch 4/25\n",
      "7/7 [==============================] - 19s 3s/step - loss: 49.8948 - binary_accuracy: 0.7814 - val_loss: 29.6816 - val_binary_accuracy: 0.6078\n",
      "Epoch 5/25\n",
      "7/7 [==============================] - 21s 3s/step - loss: 76.4719 - binary_accuracy: 0.7283 - val_loss: 82.8267 - val_binary_accuracy: 0.5294\n",
      "Epoch 6/25\n",
      "7/7 [==============================] - 22s 3s/step - loss: 37.9948 - binary_accuracy: 0.7710 - val_loss: 79.5323 - val_binary_accuracy: 0.4706\n",
      "Epoch 7/25\n",
      "7/7 [==============================] - 19s 3s/step - loss: 18.0116 - binary_accuracy: 0.8532 - val_loss: 196.5340 - val_binary_accuracy: 0.3922\n",
      "Epoch 8/25\n",
      "7/7 [==============================] - 20s 3s/step - loss: 10.2973 - binary_accuracy: 0.7825 - val_loss: 10.6856 - val_binary_accuracy: 0.7255\n",
      "Epoch 9/25\n",
      "7/7 [==============================] - 20s 3s/step - loss: 18.7553 - binary_accuracy: 0.8197 - val_loss: 62.7360 - val_binary_accuracy: 0.4314\n",
      "Epoch 10/25\n",
      "7/7 [==============================] - 18s 3s/step - loss: 12.6809 - binary_accuracy: 0.8407 - val_loss: 95.6502 - val_binary_accuracy: 0.4510\n",
      "Epoch 11/25\n",
      "7/7 [==============================] - 19s 3s/step - loss: 6.3952 - binary_accuracy: 0.9227 - val_loss: 132.5078 - val_binary_accuracy: 0.4314\n",
      "Epoch 12/25\n",
      "7/7 [==============================] - 18s 2s/step - loss: 4.7487 - binary_accuracy: 0.9590 - val_loss: 75.6461 - val_binary_accuracy: 0.4510\n",
      "Epoch 13/25\n",
      "7/7 [==============================] - 19s 3s/step - loss: 3.6778 - binary_accuracy: 0.9099 - val_loss: 68.5034 - val_binary_accuracy: 0.4706\n",
      "Epoch 14/25\n",
      "7/7 [==============================] - 21s 3s/step - loss: 7.1032 - binary_accuracy: 0.8782 - val_loss: 42.9909 - val_binary_accuracy: 0.5098\n",
      "Epoch 15/25\n",
      "7/7 [==============================] - 18s 2s/step - loss: 1.7393 - binary_accuracy: 0.9532 - val_loss: 37.6235 - val_binary_accuracy: 0.5294\n",
      "Epoch 16/25\n",
      "7/7 [==============================] - 20s 3s/step - loss: 2.6435 - binary_accuracy: 0.9586 - val_loss: 12.4710 - val_binary_accuracy: 0.6667\n",
      "Epoch 17/25\n",
      "7/7 [==============================] - 22s 3s/step - loss: 1.2662 - binary_accuracy: 0.9243 - val_loss: 21.5027 - val_binary_accuracy: 0.6078\n",
      "Epoch 18/25\n",
      "7/7 [==============================] - 16s 2s/step - loss: 0.2246 - binary_accuracy: 0.9954 - val_loss: 12.8169 - val_binary_accuracy: 0.7059\n",
      "Epoch 19/25\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.2764 - binary_accuracy: 0.9835 - val_loss: 17.7606 - val_binary_accuracy: 0.6471\n",
      "Epoch 20/25\n",
      "7/7 [==============================] - 20s 3s/step - loss: 5.3584e-04 - binary_accuracy: 1.0000 - val_loss: 17.6695 - val_binary_accuracy: 0.6667\n",
      "Epoch 21/25\n",
      "7/7 [==============================] - 19s 3s/step - loss: 0.0757 - binary_accuracy: 0.9954 - val_loss: 26.0068 - val_binary_accuracy: 0.6078\n",
      "Epoch 22/25\n",
      "7/7 [==============================] - 19s 3s/step - loss: 0.2128 - binary_accuracy: 0.9855 - val_loss: 8.9565 - val_binary_accuracy: 0.7255\n",
      "Epoch 23/25\n",
      "7/7 [==============================] - 19s 3s/step - loss: 0.1509 - binary_accuracy: 0.9823 - val_loss: 6.7791 - val_binary_accuracy: 0.8627\n",
      "Epoch 24/25\n",
      "7/7 [==============================] - 24s 3s/step - loss: 1.9378e-11 - binary_accuracy: 1.0000 - val_loss: 7.0023 - val_binary_accuracy: 0.8627\n",
      "Epoch 25/25\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.0019 - binary_accuracy: 0.9988 - val_loss: 7.5541 - val_binary_accuracy: 0.8039\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_path = 'models/best_classifier.h5'\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Save best model according to its validation set binary accuracy\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_binary_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "neural_net = model.fit(X_train, y_train, batch_size=32, epochs = 25, shuffle=True, validation_data = (X_test, y_test), callbacks=[tensorboard_callback, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7/7 [==============================] - 17s 3s/step - loss: 38.2056 - binary_accuracy: 0.6832 - val_loss: 47.7803 - val_binary_accuracy: 0.4706\n",
      "Epoch 2/25\n",
      "7/7 [==============================] - 20s 3s/step - loss: 15.5343 - binary_accuracy: 0.7624 - val_loss: 154.2070 - val_binary_accuracy: 0.3922\n",
      "Epoch 3/25\n",
      "7/7 [==============================] - 22s 3s/step - loss: 39.8518 - binary_accuracy: 0.6733 - val_loss: 52.2967 - val_binary_accuracy: 0.6078\n",
      "Epoch 4/25\n",
      "7/7 [==============================] - 20s 3s/step - loss: 34.3655 - binary_accuracy: 0.6436 - val_loss: 12.1343 - val_binary_accuracy: 0.6275\n",
      "Epoch 5/25\n",
      "7/7 [==============================] - 20s 3s/step - loss: 11.9912 - binary_accuracy: 0.7327 - val_loss: 8.6164 - val_binary_accuracy: 0.6275\n",
      "Epoch 6/25\n",
      "7/7 [==============================] - 19s 3s/step - loss: 4.9548 - binary_accuracy: 0.8020 - val_loss: 3.2740 - val_binary_accuracy: 0.6275\n",
      "Epoch 7/25\n",
      "7/7 [==============================] - 22s 3s/step - loss: 1.3938 - binary_accuracy: 0.7921 - val_loss: 2.0545 - val_binary_accuracy: 0.6275\n",
      "Epoch 8/25\n",
      "7/7 [==============================] - 20s 3s/step - loss: 1.4680 - binary_accuracy: 0.7822 - val_loss: 1.3303 - val_binary_accuracy: 0.7451\n",
      "Epoch 9/25\n",
      "7/7 [==============================] - 24s 3s/step - loss: 1.3738 - binary_accuracy: 0.8020 - val_loss: 0.8634 - val_binary_accuracy: 0.7843\n",
      "Epoch 10/25\n",
      "7/7 [==============================] - 17s 2s/step - loss: 0.6514 - binary_accuracy: 0.7871 - val_loss: 1.3159 - val_binary_accuracy: 0.6078\n",
      "Epoch 11/25\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.6033 - binary_accuracy: 0.8218 - val_loss: 0.4937 - val_binary_accuracy: 0.8039\n",
      "Epoch 12/25\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.3792 - binary_accuracy: 0.8366 - val_loss: 0.4533 - val_binary_accuracy: 0.8235\n",
      "Epoch 13/25\n",
      "7/7 [==============================] - 20s 3s/step - loss: 0.2987 - binary_accuracy: 0.8663 - val_loss: 0.4336 - val_binary_accuracy: 0.8235\n",
      "Epoch 14/25\n",
      "7/7 [==============================] - 20s 2s/step - loss: 0.2426 - binary_accuracy: 0.9109 - val_loss: 0.4090 - val_binary_accuracy: 0.8824\n",
      "Epoch 15/25\n",
      "7/7 [==============================] - 18s 3s/step - loss: 0.3055 - binary_accuracy: 0.8911 - val_loss: 0.4114 - val_binary_accuracy: 0.8039\n",
      "Epoch 16/25\n",
      "7/7 [==============================] - 19s 3s/step - loss: 0.2564 - binary_accuracy: 0.8911 - val_loss: 0.4340 - val_binary_accuracy: 0.7451\n",
      "Epoch 17/25\n",
      "7/7 [==============================] - 18s 2s/step - loss: 0.2147 - binary_accuracy: 0.9109 - val_loss: 0.4306 - val_binary_accuracy: 0.7647\n",
      "Epoch 18/25\n",
      "7/7 [==============================] - 17s 2s/step - loss: 0.2363 - binary_accuracy: 0.9010 - val_loss: 0.4144 - val_binary_accuracy: 0.8627\n",
      "Epoch 19/25\n",
      "7/7 [==============================] - 16s 2s/step - loss: 0.2042 - binary_accuracy: 0.9455 - val_loss: 0.3846 - val_binary_accuracy: 0.8431\n",
      "Epoch 20/25\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.2370 - binary_accuracy: 0.8960 - val_loss: 0.3966 - val_binary_accuracy: 0.8235\n",
      "Epoch 21/25\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.2165 - binary_accuracy: 0.8960 - val_loss: 0.4235 - val_binary_accuracy: 0.8431\n",
      "Epoch 22/25\n",
      "7/7 [==============================] - 18s 2s/step - loss: 0.1633 - binary_accuracy: 0.9257 - val_loss: 0.4318 - val_binary_accuracy: 0.8431\n",
      "Epoch 23/25\n",
      "7/7 [==============================] - 15s 2s/step - loss: 0.2415 - binary_accuracy: 0.9059 - val_loss: 0.4621 - val_binary_accuracy: 0.8235\n",
      "Epoch 24/25\n",
      "7/7 [==============================] - 17s 3s/step - loss: 0.2281 - binary_accuracy: 0.9158 - val_loss: 0.4222 - val_binary_accuracy: 0.8235\n",
      "Epoch 25/25\n",
      "7/7 [==============================] - 16s 2s/step - loss: 0.1914 - binary_accuracy: 0.9257 - val_loss: 0.4378 - val_binary_accuracy: 0.8235\n"
     ]
    }
   ],
   "source": [
    "# Test model with rotations/flips, validation accuracy seems significantly worse\n",
    "\n",
    "neural_net = model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=25, shuffle=True, validation_data = (X_test, y_test), callbacks=[tensorboard_callback, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803921568627451"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "tta_steps = 10\n",
    "predictions = []\n",
    "\n",
    "for i in range(tta_steps):\n",
    "    preds = (model.predict(datagen.flow(X_test, batch_size=32, shuffle=False)) > 0.5).astype(\"int32\")\n",
    "    predictions.append(preds)\n",
    "\n",
    "np.mean(np.equal(y_test, stats.mode(predictions)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60784314])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
